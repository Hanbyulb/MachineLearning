{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset\n",
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "3KkwQV7A9ZPQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda')"
      ],
      "metadata": {
        "id": "cYtp8rgC0QMA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CIkoN7R47_BO"
      },
      "outputs": [],
      "source": [
        "# import mnist data\n",
        "from sklearn.datasets import fetch_openml\n",
        "mnist = fetch_openml('mnist_784', cache=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = mnist.data.astype('float32')\n",
        "y = mnist.target.astype('int64')"
      ],
      "metadata": {
        "id": "24ZYxQ048D-t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y = pd.DataFrame(y)\n",
        "df = pd.concat([X, Y], axis=1) "
      ],
      "metadata": {
        "id": "313ZjRyu8IWJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ratio = 0.7\n",
        "val_ratio = 0.15\n",
        "test_ratio = 0.15"
      ],
      "metadata": {
        "id": "aKgcLOwS9dCW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "df0 = df[df['class']==0]\n",
        "train_idx0 = int(len(df0) * train_ratio)\n",
        "val_idx0 = int(len(df0) * (train_ratio + val_ratio))\n",
        "\n",
        "train_set0 = df0[:train_idx0]\n",
        "val_set0 = df0[train_idx0:val_idx0]\n",
        "test_set0 = df0[val_idx0:]\n",
        "\n",
        "#\n",
        "df1 = df[df['class']==1]\n",
        "train_idx1 = int(len(df1) * train_ratio)\n",
        "val_idx1 = int(len(df1) * (train_ratio + val_ratio))\n",
        "\n",
        "train_set1 = df1[:train_idx1]\n",
        "val_set1 = df1[train_idx1:val_idx1]\n",
        "test_set1 = df1[val_idx1:]\n",
        "\n",
        "#\n",
        "df2 = df[df['class']==2]\n",
        "train_idx2 = int(len(df2) * train_ratio)\n",
        "val_idx2 = int(len(df2) * (train_ratio + val_ratio))\n",
        "\n",
        "train_set2 = df2[:train_idx2]\n",
        "val_set2 = df2[train_idx2:val_idx2]\n",
        "test_set2 = df2[val_idx2:]\n",
        "\n",
        "#\n",
        "df3 = df[df['class']==3]\n",
        "train_idx3 = int(len(df3) * train_ratio)\n",
        "val_idx3 = int(len(df3) * (train_ratio + val_ratio))\n",
        "\n",
        "train_set3 = df3[:train_idx3]\n",
        "val_set3 = df3[train_idx3:val_idx0]\n",
        "test_set3 = df3[val_idx3:]\n",
        "\n",
        "#\n",
        "df4 = df[df['class']==4]\n",
        "train_idx4 = int(len(df4) * train_ratio)\n",
        "val_idx4 = int(len(df4) * (train_ratio + val_ratio))\n",
        "\n",
        "train_set4 = df4[:train_idx4]\n",
        "val_set4 = df4[train_idx4:val_idx4]\n",
        "test_set4 = df4[val_idx4:]\n",
        "\n",
        "#\n",
        "df5 = df[df['class']==5]\n",
        "train_idx5 = int(len(df5) * train_ratio)\n",
        "val_idx5 = int(len(df5) * (train_ratio + val_ratio))\n",
        "\n",
        "train_set5 = df5[:train_idx5]\n",
        "val_set5 = df5[train_idx5:val_idx5]\n",
        "test_set5 = df5[val_idx5:]\n",
        "\n",
        "#\n",
        "df6 = df[df['class']==6]\n",
        "train_idx6 = int(len(df6) * train_ratio)\n",
        "val_idx6 = int(len(df6) * (train_ratio + val_ratio))\n",
        "\n",
        "train_set6 = df6[:train_idx6]\n",
        "val_set6 = df6[train_idx6:val_idx6]\n",
        "test_set6 = df6[val_idx6:]\n",
        "\n",
        "#\n",
        "df7 = df[df['class']==7]\n",
        "train_idx7 = int(len(df7) * train_ratio)\n",
        "val_idx7 = int(len(df7) * (train_ratio + val_ratio))\n",
        "\n",
        "train_set7 = df7[:train_idx7]\n",
        "val_set7 = df7[train_idx7:val_idx7]\n",
        "test_set7 = df7[val_idx7:]\n",
        "\n",
        "#\n",
        "df8 = df[df['class']==8]\n",
        "train_idx8 = int(len(df8) * train_ratio)\n",
        "val_idx8 = int(len(df8) * (train_ratio + val_ratio))\n",
        "\n",
        "train_set8 = df8[:train_idx8]\n",
        "val_set8 = df8[train_idx8:val_idx8]\n",
        "test_set8 = df8[val_idx8:]\n",
        "\n",
        "#\n",
        "df9 = df[df['class']==9]\n",
        "train_idx9 = int(len(df9) * train_ratio)\n",
        "val_idx9 = int(len(df9) * (train_ratio + val_ratio))\n",
        "\n",
        "train_set9 = df9[:train_idx9]\n",
        "val_set9 = df9[train_idx9:val_idx9]\n",
        "test_set9 = df9[val_idx9:]"
      ],
      "metadata": {
        "id": "eNmYPrzK9fbE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Binary Classification"
      ],
      "metadata": {
        "id": "uVS89OxLWzce"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "epochs = 5"
      ],
      "metadata": {
        "id": "CfWy8e2nYO-k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainB_set = pd.concat([train_set2, train_set3])\n",
        "trainB_set = trainB_set.sample(frac=1)\n",
        "x_trainB = trainB_set.drop(['class'], axis=1)\n",
        "y_trainB = trainB_set['class']\n",
        "\n",
        "valB_set = pd.concat([val_set2, val_set3])\n",
        "valB_set = valB_set.sample(frac=1)\n",
        "x_valB = valB_set.drop(['class'], axis=1)\n",
        "y_valB = valB_set['class']\n",
        "\n",
        "testB_set = pd.concat([test_set2, test_set3])\n",
        "testB_set = testB_set.sample(frac=1)\n",
        "x_testB = testB_set.drop(['class'], axis=1)\n",
        "y_testB = testB_set['class']"
      ],
      "metadata": {
        "id": "MMIy-OH3XPA_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_trainB = torch.from_numpy(x_trainB.values).squeeze()\n",
        "y_trainB = torch.from_numpy(y_trainB.values).squeeze()\n",
        "\n",
        "x_valB = torch.from_numpy(x_valB.values).squeeze()\n",
        "y_valB = torch.from_numpy(y_valB.values).squeeze()\n",
        "\n",
        "x_testB = torch.from_numpy(x_testB.values).squeeze()\n",
        "y_testB = torch.from_numpy(y_testB.values).squeeze()"
      ],
      "metadata": {
        "id": "2eEr1uvSXcVw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainsetB = TensorDataset(x_trainB, y_trainB)\n",
        "valsetB = TensorDataset(x_valB, y_valB)\n",
        "testsetB = TensorDataset(x_testB, y_testB)"
      ],
      "metadata": {
        "id": "f36-TzN4YEse"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainB_loader = torch.utils.data.DataLoader(dataset = trainsetB, batch_size = batch_size,\n",
        "    shuffle = True) \n",
        "\n",
        "valB_loader = torch.utils.data.DataLoader(dataset = valsetB, batch_size = batch_size,\n",
        "    shuffle = False)\n",
        "\n",
        "testB_loader = torch.utils.data.DataLoader(dataset = testsetB, batch_size = batch_size,\n",
        "    shuffle = False)"
      ],
      "metadata": {
        "id": "7FRpOvUYYMiV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YgWkomNmY2Mb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multiclass Classification"
      ],
      "metadata": {
        "id": "ulK7hISiXJVt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "epochs = 30"
      ],
      "metadata": {
        "id": "I6zKNmcO-wI9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = pd.concat([train_set0, train_set1, train_set2, train_set3, train_set4, train_set5, train_set6, train_set7, train_set8, train_set9])\n",
        "train_set = train_set.sample(frac=1)\n",
        "x_train = train_set.drop(['class'], axis=1)\n",
        "y_train = train_set['class']\n",
        "\n",
        "val_set = pd.concat([val_set0, val_set1, val_set2, val_set3, val_set4, val_set5, val_set6, val_set7, val_set8, val_set9])\n",
        "val_set = val_set.sample(frac=1)\n",
        "x_val = val_set.drop(['class'], axis=1)\n",
        "y_val = val_set['class']\n",
        "\n",
        "test_set = pd.concat([test_set0, test_set1, test_set2, test_set3, test_set4, test_set5, test_set6, test_set7, test_set8, test_set9])\n",
        "test_set = test_set.sample(frac=1)\n",
        "x_test = test_set.drop(['class'], axis=1)\n",
        "y_test = test_set['class']"
      ],
      "metadata": {
        "id": "UDfawU-e989h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = torch.from_numpy(x_train.values).squeeze()\n",
        "y_train = torch.from_numpy(y_train.values).squeeze()\n",
        "\n",
        "x_val = torch.from_numpy(x_val.values).squeeze()\n",
        "y_val = torch.from_numpy(y_val.values).squeeze()\n",
        "\n",
        "x_test = torch.from_numpy(x_test.values).squeeze()\n",
        "y_test = torch.from_numpy(y_test.values).squeeze()"
      ],
      "metadata": {
        "id": "zfB8Z1Andt6d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainset = TensorDataset(x_train, y_train)\n",
        "valset = TensorDataset(x_val, y_val)\n",
        "testset = TensorDataset(x_test, y_test)"
      ],
      "metadata": {
        "id": "D20b6cIjaY5k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(dataset = trainset, batch_size = batch_size,\n",
        "    shuffle = True) \n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(dataset = valset, batch_size = batch_size,\n",
        "    shuffle = False)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset = testset, batch_size = batch_size,\n",
        "    shuffle = False)"
      ],
      "metadata": {
        "id": "NqXJaygZ_HsW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(torch.nn.Module):\n",
        "  def __init__(self, input_size, hidden1_size, hidden2_size, output_size):\n",
        "    super(MLP, self).__init__()\n",
        "    self.linear1 = nn.Linear(input_size, hidden1_size)\n",
        "    self.linear2 = nn.Linear(hidden1_size, hidden2_size)\n",
        "    self.linear3 = nn.Linear(hidden2_size, output_size)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = x.view(-1, 28*28)\n",
        "    x = self.linear1(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.linear2(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.linear3(x)\n",
        "    x = F.log_softmax(x, dim=1)\n",
        "    return x"
      ],
      "metadata": {
        "id": "rcQ3aTvDGJiL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_size, hidden1_size, hidden2_size, output_size = 784, 512, 256, 10"
      ],
      "metadata": {
        "id": "qIVu9_zmMU8L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MLP(input_size, hidden1_size, hidden2_size, output_size).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Sxn30_3x8tS",
        "outputId": "fea5e4fd-84f3-4266-b80e-cf300b1ebe36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLP(\n",
            "  (linear1): Linear(in_features=784, out_features=512, bias=True)\n",
            "  (linear2): Linear(in_features=512, out_features=256, bias=True)\n",
            "  (linear3): Linear(in_features=256, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "  avg_cost = 0\n",
        "\n",
        "  for X_train, Y_train in train_loader:\n",
        "    X_train = x_train.to(device)\n",
        "    Y_train = y_train.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    hypothesis = model(X_train)\n",
        "    cost = criterion(hypothesis, Y_train)\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    avg_cost += cost / len(train_loader)\n",
        "  print('Epoch:', '%d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ks5nb6rB0oI-",
        "outputId": "fe76db82-656e-44b0-b2ee-8a5e19781d16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 cost = 0.088308729\n",
            "Epoch: 2 cost = 0.066851333\n",
            "Epoch: 3 cost = 0.045797598\n",
            "Epoch: 4 cost = 0.040699221\n",
            "Epoch: 5 cost = 0.408411592\n",
            "Epoch: 6 cost = 0.273157805\n",
            "Epoch: 7 cost = 0.104629278\n",
            "Epoch: 8 cost = 0.078526162\n",
            "Epoch: 9 cost = 0.064833306\n",
            "Epoch: 10 cost = 0.061741535\n",
            "Epoch: 11 cost = 0.056673057\n",
            "Epoch: 12 cost = 0.054569043\n",
            "Epoch: 13 cost = 0.054174311\n",
            "Epoch: 14 cost = 0.050991293\n",
            "Epoch: 15 cost = 0.056969136\n",
            "Epoch: 16 cost = 0.048612576\n",
            "Epoch: 17 cost = 0.047213718\n",
            "Epoch: 18 cost = 0.050552454\n",
            "Epoch: 19 cost = 0.047129326\n",
            "Epoch: 20 cost = 0.048563264\n",
            "Epoch: 21 cost = 0.045298584\n",
            "Epoch: 22 cost = 0.045303773\n",
            "Epoch: 23 cost = 0.048489686\n",
            "Epoch: 24 cost = 0.041968741\n",
            "Epoch: 25 cost = 0.048134044\n",
            "Epoch: 26 cost = 0.045481518\n",
            "Epoch: 27 cost = 0.045654807\n",
            "Epoch: 28 cost = 0.042930920\n",
            "Epoch: 29 cost = 0.039233278\n",
            "Epoch: 30 cost = 0.043101478\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  X_test, Y_test = x_test.to(device), y_test.to(device)\n",
        "\n",
        "  prediction = model(X_test)\n",
        "  correct_prediction = torch.argmax(prediction, 1) == Y_test\n",
        "  accuracy = correct_prediction.float().mean()\n",
        "  print('Accuracy: ', accuracy.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N5w8cP003KCo",
        "outputId": "d9459d20-73be-468e-b92b-da7024c9743e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.933929979801178\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oGQpe43pEVTe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}